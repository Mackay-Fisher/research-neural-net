{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Step: 0, Loss: [[6.8936663]]\n",
      "Step: 1000, Loss: [[0.53268105]]\n",
      "Step: 2000, Loss: [[0.5322491]]\n",
      "Step: 3000, Loss: [[0.5316452]]\n",
      "Step: 4000, Loss: [[0.52959514]]\n",
      "Step: 5000, Loss: [[0.417171]]\n",
      "Step: 6000, Loss: [[0.13875267]]\n",
      "Step: 7000, Loss: [[0.06955291]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ODENet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ODENet, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(100, activation='sigmoid')\n",
    "        self.dense2 = tf.keras.layers.Dense(100, activation='sigmoid')\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='linear')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "model = ODENet()\n",
    "\n",
    "def loss_fn(model, x):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x)\n",
    "        y = model(x)\n",
    "        dy_dx = tape.gradient(y, x)\n",
    "    d2y_dx2 = tape.gradient(dy_dx, x)\n",
    "\n",
    "    # Residual from the differential equation\n",
    "    residual = d2y_dx2 - y\n",
    "\n",
    "    # Calculate the loss as the squared error\n",
    "    loss = tf.reduce_mean(tf.square(residual))\n",
    "\n",
    "    # Add boundary conditions to the loss\n",
    "    loss += tf.square(model(tf.constant([[0.0]], dtype=tf.float32)))\n",
    "    loss += tf.square(model(tf.constant([[1.0]], dtype=tf.float32)) - 1.0)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "def train_step(model, x):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, x)\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return loss\n",
    "\n",
    "x_samples = tf.convert_to_tensor(np.linspace(0, 5, 500).reshape(-1, 1), dtype=tf.float32)\n",
    "\n",
    "for step in range(10000):\n",
    "    loss = train_step(model, x_samples)\n",
    "    if step % 1000 == 0:\n",
    "        print(f\"Step: {step}, Loss: {loss.numpy()}\")\n",
    "\n",
    "# Define the analytical solution\n",
    "def analytical_solution(t):\n",
    "    e = np.exp(1)\n",
    "    return (np.exp(t) - np.exp(-t) - (e - e**-1) * t) / (e - e**-1)\n",
    "\n",
    "x_test = np.linspace(0, 5, 1000).reshape(-1, 1)\n",
    "y_true = analytical_solution(x_test)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_test, y_true, label='Analytical Solution', color='blue')\n",
    "plt.plot(x_test, y_pred, label='Model Prediction', color='red', linestyle='--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Comparison of Analytical Solution and Model Prediction over [0, 5]')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
